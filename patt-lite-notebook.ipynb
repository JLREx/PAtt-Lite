{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afba9042",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-05T03:08:04.363918Z",
     "iopub.status.busy": "2024-04-05T03:08:04.359563Z",
     "iopub.status.idle": "2024-04-05T03:08:09.251117Z",
     "shell.execute_reply": "2024-04-05T03:08:09.250372Z",
     "shell.execute_reply.started": "2024-04-05T03:06:26.029431Z"
    },
    "papermill": {
     "duration": 4.906285,
     "end_time": "2024-04-05T03:08:09.251280",
     "exception": false,
     "start_time": "2024-04-05T03:08:04.344995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe0490b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T03:08:09.268693Z",
     "iopub.status.busy": "2024-04-05T03:08:09.267799Z",
     "iopub.status.idle": "2024-04-05T03:08:09.270493Z",
     "shell.execute_reply": "2024-04-05T03:08:09.269879Z",
     "shell.execute_reply.started": "2024-04-05T03:06:31.268251Z"
    },
    "papermill": {
     "duration": 0.013423,
     "end_time": "2024-04-05T03:08:09.270616",
     "exception": false,
     "start_time": "2024-04-05T03:08:09.257193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 8\n",
    "IMG_SHAPE = (120, 120, 3)\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "TRAIN_EPOCH = 100\n",
    "TRAIN_LR = 1e-3\n",
    "TRAIN_ES_PATIENCE = 5\n",
    "TRAIN_LR_PATIENCE = 3\n",
    "TRAIN_MIN_LR = 1e-6\n",
    "TRAIN_DROPOUT = 0.1\n",
    "\n",
    "FT_EPOCH = 500\n",
    "FT_LR = 1e-5\n",
    "FT_LR_DECAY_STEP = 80.0\n",
    "FT_LR_DECAY_RATE = 1\n",
    "FT_ES_PATIENCE = 20\n",
    "FT_DROPOUT = 0.2\n",
    "\n",
    "ES_LR_MIN_DELTA = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d318d802",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T03:08:09.298321Z",
     "iopub.status.busy": "2024-04-05T03:08:09.297711Z",
     "iopub.status.idle": "2024-04-05T03:08:21.833062Z",
     "shell.execute_reply": "2024-04-05T03:08:21.832391Z",
     "shell.execute_reply.started": "2024-04-05T03:06:31.275621Z"
    },
    "papermill": {
     "duration": 12.557677,
     "end_time": "2024-04-05T03:08:21.833202",
     "exception": false,
     "start_time": "2024-04-05T03:08:09.275525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load your data here, PAtt-Lite was trained with h5py for shorter loading time\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "print(\"Shape of train_sample: {}\".format(X_train.shape))\n",
    "print(\"Shape of train_label: {}\".format(y_train.shape))\n",
    "print(\"Shape of valid_sample: {}\".format(X_valid.shape))\n",
    "print(\"Shape of valid_label: {}\".format(y_valid.shape))\n",
    "print(\"Shape of test_sample: {}\".format(X_test.shape))\n",
    "print(\"Shape of test_label: {}\".format(y_test.shape))\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e772bf90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T03:08:21.872945Z",
     "iopub.status.busy": "2024-04-05T03:08:21.872214Z",
     "iopub.status.idle": "2024-04-05T04:11:01.037919Z",
     "shell.execute_reply": "2024-04-05T04:11:01.038380Z",
     "shell.execute_reply.started": "2024-04-05T03:06:43.580536Z"
    },
    "papermill": {
     "duration": 3759.199616,
     "end_time": "2024-04-05T04:11:01.038616",
     "exception": false,
     "start_time": "2024-04-05T03:08:21.839000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model Building\n",
    "input_layer = tf.keras.Input(shape=IMG_SHAPE, name='universal_input')\n",
    "sample_resizing = tf.keras.layers.experimental.preprocessing.Resizing(224, 224, name=\"resize\")\n",
    "data_augmentation = tf.keras.Sequential([tf.keras.layers.RandomFlip(mode='horizontal'), \n",
    "                                        tf.keras.layers.RandomContrast(factor=0.3)], name=\"augmentation\")\n",
    "preprocess_input = tf.keras.applications.mobilenet.preprocess_input\n",
    "\n",
    "backbone = tf.keras.applications.mobilenet.MobileNet(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "backbone.trainable = False\n",
    "base_model = tf.keras.Model(backbone.input, backbone.layers[-29].output, name='base_model')\n",
    "\n",
    "self_attention = tf.keras.layers.Attention(use_scale=True, name='attention')\n",
    "patch_extraction = tf.keras.Sequential([\n",
    "    tf.keras.layers.SeparableConv2D(256, kernel_size=4, strides=4, padding='same', activation='relu'), \n",
    "    tf.keras.layers.SeparableConv2D(256, kernel_size=2, strides=2, padding='valid', activation='relu'), \n",
    "    tf.keras.layers.Conv2D(256, kernel_size=1, strides=1, padding='valid', activation='relu')\n",
    "], name='patch_extraction')\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D(name='gap')\n",
    "pre_classification = tf.keras.Sequential([tf.keras.layers.Dense(32, activation='relu'), \n",
    "                                          tf.keras.layers.BatchNormalization()], name='pre_classification')\n",
    "prediction_layer = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\", name='classification_head')\n",
    "\n",
    "inputs = input_layer\n",
    "x = sample_resizing(inputs)\n",
    "x = data_augmentation(x)\n",
    "x = preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = patch_extraction(x)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(TRAIN_DROPOUT)(x)\n",
    "x = pre_classification(x)\n",
    "x = self_attention([x, x])\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs, name='train-head')\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=TRAIN_LR, global_clipnorm=3.0), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training Procedure\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=TRAIN_ES_PATIENCE, min_delta=ES_LR_MIN_DELTA, restore_best_weights=True)\n",
    "learning_rate_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=TRAIN_LR_PATIENCE, verbose=0, min_delta=ES_LR_MIN_DELTA, min_lr=TRAIN_MIN_LR)\n",
    "history = model.fit(X_train, y_train, epochs=TRAIN_EPOCH, batch_size=BATCH_SIZE, validation_data=(X_valid, y_valid), verbose=0, \n",
    "                    class_weight=class_weights, callbacks=[early_stopping_callback, learning_rate_callback])\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Model Finetuning\n",
    "print(\"\\nFinetuning ...\")\n",
    "unfreeze = 59\n",
    "base_model.trainable = True\n",
    "fine_tune_from = len(base_model.layers) - unfreeze\n",
    "for layer in base_model.layers[:fine_tune_from]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[fine_tune_from:]:\n",
    "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        layer.trainable = False\n",
    "\n",
    "inputs = input_layer\n",
    "x = sample_resizing(inputs)\n",
    "x = data_augmentation(x)\n",
    "x = preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = patch_extraction(x)\n",
    "x = tf.keras.layers.SpatialDropout2D(FT_DROPOUT)(x)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(FT_DROPOUT)(x)\n",
    "x = pre_classification(x)\n",
    "x = self_attention([x, x])\n",
    "x = tf.keras.layers.Dropout(FT_DROPOUT)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs, name='finetune-backbone')\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=FT_LR, global_clipnorm=3.0), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training Procedure\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', min_delta=ES_LR_MIN_DELTA, patience=FT_ES_PATIENCE, restore_best_weights=True)\n",
    "scheduler = keras.optimizers.schedules.InverseTimeDecay(initial_learning_rate=FT_LR, decay_steps=FT_LR_DECAY_STEP, decay_rate=FT_LR_DECAY_RATE)\n",
    "scheduler_callback = tf.keras.callbacks.LearningRateScheduler(schedule=scheduler)\n",
    "\n",
    "history_finetune = model.fit(X_train, y_train, epochs=FT_EPOCH, batch_size=BATCH_SIZE, validation_data=(X_valid, y_valid), verbose=0, \n",
    "                             initial_epoch=history.epoch[-TRAIN_ES_PATIENCE], callbacks=[early_stopping_callback, scheduler_callback, tensorboard_callback])\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1718596,
     "sourceId": 5546170,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3788.698907,
   "end_time": "2024-04-05T04:11:04.022881",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-05T03:07:55.323974",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
